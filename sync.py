import gspread
from google.oauth2.service_account import Credentials
import threading
import queue
import time
import re
from datetime import datetime
from tkinter import messagebox
from config import CREDENTIALS_PATH, EXCEL_PATH

_group_queue = queue.Queue()
_latest_groups = None

#æ•¸å­—è½‰column
def get_column_letter(n):
    result = ""
    while n > 0:
        n, rem = divmod(n - 1, 26)  #26é€²ä½åˆ¶
        result = chr(65 + rem) + result
    return result

#å°‡EXCELçš„æ¨™é¡Œæ¬„ä½å¾ç¶²é åŸå§‹æ ¼å¼è½‰æˆè‡ªå®šç¾©
def clean_column_name(name):
    if name == "å…¬å¸åç¨±":
        return name

    #è™•ç†EPSã€FREE CASH FLOWã€DEBT + TTM
    #æ­£å‰‡è¡¨é”å¼æ¯”å°EPS (TTM) æˆ– Free Cash Flow (TTM) æˆ– Total Debt (TTM)
    #.*è¬ç”¨å­—å…ƒ
    match_ttm = re.search(r"(EPS|Free Cash Flow|Total Debt).*\(TTM\)", name)
    if match_ttm:
        #å¦‚æœæ¯”å°æˆåŠŸï¼Œå°‡å­—ä¸²ä¿®æ”¹ç‚º EPS(TTM)ã€Free Cash Flow(TTM)ã€Total Debt(TTM)
        return f"{match_ttm.group(1)}(TTM)"

    #è™•ç†FYå¹´ä»½æ¬„ä½
    # æ­£å‰‡è¡¨é”å¼æ¯”å°EPS (å¹´åˆ†) æˆ– Free Cash Flow (å¹´åˆ†) æˆ– Total Debt (å¹´åˆ†)
    #\d{4} è¡¨è¥¿å…ƒå¹´
    match_year = re.search(r"(EPS|Free Cash Flow|Total Debt).*?\(FY (\d{4})\)", name)
    if match_year:
        return f"{match_year.group(1)}({match_year.group(2)})"

    return name.strip()

def extract_year(col):
    match = re.search(r"\((TTM|\d{4})\)", col)
    #å¦‚æœæœ‰æŠ“åˆ°TTMæˆ–æ˜¯å¹´åˆ†
    if match:
        val = match.group(1)
        #å¦‚æœæ˜¯TTMå‰‡å›å‚³9999ã€å¦‚æœæ˜¯å¹´ä»½å‰‡å›å‚³å¹´åˆ†ã€å¦‚æœéƒ½ä¸æ˜¯å‰‡å›å‚³-1
        return 9999 if val == "TTM" else int(val)
    return -1


def sort_headers_with_priority(headers, priority_list):
    headers_set = set(headers)
    ordered = []
    for col in priority_list:
        if col in headers_set:
            ordered.append(col)
    for col in headers:
        if col not in ordered:
            ordered.append(col)
    return ordered

def smart_write_to_google_sheet(
    data_rows,
    extra_data_dict=None,
    spreadsheet_id=None,
    sheet_name="Crawl_data",
    log_fn=None,
):
    def do_update():
        if not spreadsheet_id:
            log_fn(f"âŒ æœªå¯«å…¥ Spreadsheet ID")
            return

        credentials = Credentials.from_service_account_file(
            CREDENTIALS_PATH,
            scopes=["https://www.googleapis.com/auth/spreadsheets"]
        )
        gc = gspread.authorize(credentials)
        sh = gc.open_by_key(spreadsheet_id)

        try:
            worksheet = sh.worksheet(sheet_name)
        except gspread.exceptions.WorksheetNotFound:
            worksheet = sh.add_worksheet(title=sheet_name, rows="1000", cols="40")

        rows = worksheet.get_all_values()
        current_headers = rows[0] if rows else []

        static_cols = ["è‚¡ç¥¨ä»£ç¢¼", "å…¬å¸åç¨±", "SharesOut", "PE Ratio", "Price Target"]

        dynamic_keys = set()
        if extra_data_dict:
            for val in extra_data_dict.values():
                for key in val:
                    if key != "å…¬å¸åç¨±":
                        dynamic_keys.add(key)

        cleaned_keys = [clean_column_name(key) for key in dynamic_keys]
        sorted_dynamic_cols = sorted(
            cleaned_keys, key=lambda c: -extract_year(c) if extract_year(c) != -1 else 0
        )

        #æ¨™é¡Œé †åº
        desired_order = [
            "è‚¡ç¥¨ä»£ç¢¼", "å…¬å¸åç¨±", "SharesOut", "PE Ratio", "Price Target",
            "EPS(TTM)", "EPS(2025)", "EPS(2024)", "EPS(2023)", "EPS(2022)", "EPS(2021)", "EPS(2020)",
            "Free Cash Flow(TTM)", "Free Cash Flow(2025)","Free Cash Flow(2024)", "Free Cash Flow(2023)", "Free Cash Flow(2022)","Free Cash Flow(2021)","Free Cash Flow(2020)",
            "Total Debt(TTM)","Total Debt(2025)","Total Debt(2024)", "Total Debt(2023)","Total Debt(2022)","Total Debt(2021)","Total Debt(2020)", "æ›´æ–°æ™‚é–“"
        ]

        # å…ˆå»ºç«‹æ¬„ä½é›†åˆï¼ŒåŒ…å«è³‡æ–™å‡ºç¾éçš„æ¬„ä½
        raw_all_headers = static_cols + sorted_dynamic_cols + ["æ›´æ–°æ™‚é–“"]

        # è‹¥æœ‰desired_orderæœ‰å‡ºç¾ä½†raw_all_headersæ²’æœ‰å‰‡appendåœ¨å¾Œé¢
        for col in desired_order:
            if col not in raw_all_headers:
                raw_all_headers.append(col)

        #ä¾æ“šä¸Šé¢çš„é †åºæ’åˆ—æ¨™é¡Œ
        all_headers = sort_headers_with_priority(raw_all_headers, desired_order)

        if current_headers != all_headers:
            if not current_headers:
                worksheet.append_row(all_headers)
            else:
                worksheet.update("A1", [all_headers])
            current_headers = all_headers

        col_index_map = {col: idx + 1 for idx, col in enumerate(current_headers)}
        existing_rows = worksheet.get_all_values()[1:]

        code_to_row = {
            row[0].strip().upper(): idx + 2
            for idx, row in enumerate(existing_rows)
            if row and row[0].strip()
        }

        for code, shares, pe, pt in data_rows:
            code_key = code.strip().upper()
            extra = extra_data_dict.get(code, {}) if extra_data_dict else {}
            company_name = extra.get("å…¬å¸åç¨±", "-")

            row_data = [""] * len(current_headers)
            row_data[col_index_map["è‚¡ç¥¨ä»£ç¢¼"] - 1] = code
            row_data[col_index_map["å…¬å¸åç¨±"] - 1] = company_name
            row_data[col_index_map["SharesOut"] - 1] = shares
            row_data[col_index_map["PE Ratio"] - 1] = pe
            row_data[col_index_map["Price Target"] - 1] = pt

            for cleaned_key in col_index_map:
                if cleaned_key in static_cols or cleaned_key == "æ›´æ–°æ™‚é–“":
                    continue  # éœæ…‹æ¬„ä½äº¤ç”±å‰é¢è™•ç†

                # å˜—è©¦å¾ extra è³‡æ–™ä¸­æ‰¾å°æ‡‰çš„åŸå§‹ key
                raw_match = next((rk for rk in extra if clean_column_name(rk) == cleaned_key), None)

                if raw_match:
                    val = extra.get(raw_match)
                    row_data[col_index_map[cleaned_key] - 1] = val if val not in [None, "", "NA", "N/A"] else "-"
                else:
                    row_data[col_index_map[cleaned_key] - 1] = "-"

            row_data[col_index_map["æ›´æ–°æ™‚é–“"] - 1] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

            try:
                if code_key in code_to_row:
                    row_num = code_to_row[code_key]
                    end_col_letter = get_column_letter(len(current_headers))
                    cell_range = f"A{row_num}:{end_col_letter}{row_num}"
                    worksheet.update(cell_range, [row_data])
                    log_fn(f"ğŸ“Œ Renew{code}|{company_name} to {row_num} row")
                else:
                    worksheet.append_row(row_data)
                    existing_rows = worksheet.get_all_values()[1:]
                    new_row = len(existing_rows) + 1  # æˆ– +2ï¼Œçœ‹ä½  header æ˜¯å¦åŒ…å«åœ¨å…§
                    log_fn(f"â• add{code}|{company_name} to {new_row} row")



            except gspread.exceptions.APIError as e:
                log_fn(f"âš ï¸ å¯«å…¥ {code} |{company_name}ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

    threading.Thread(target=do_update, daemon=True).start()

def sync_group_to_google_sheet(groups_dict, spreadsheet_id, sheet_name="Group"):
    def do_sync():
        credentials = Credentials.from_service_account_file(
            CREDENTIALS_PATH,
            scopes=["https://www.googleapis.com/auth/spreadsheets"]
        )
        gc = gspread.authorize(credentials)

        try:
            sh = gc.open_by_key(spreadsheet_id)
            if sheet_name in [ws.title for ws in sh.worksheets()]:
                worksheet = sh.worksheet(sheet_name)
                worksheet.clear()
            else:
                worksheet = sh.add_worksheet(title=sheet_name, rows="100", cols="30")
        except Exception as e:
            print(f"âŒ åŒæ­¥ Group åˆ†é å¤±æ•—ï¼š{e}")
            return

        max_len = max((len(codes) for codes in groups_dict.values()), default=0)
        rows = [list(groups_dict.keys())]
        for i in range(max_len):
            row = [groups_dict[g][i] if i < len(groups_dict[g]) else "" for g in groups_dict]
            rows.append(row)

        worksheet.update("A1", rows)

    threading.Thread(target=do_sync, daemon=True).start()

def _group_sync_worker(spreadsheet_id, sheet_name="Group"):
    global _latest_groups
    last_sync_time = 0
    debounce_seconds = 10

    while True:
        try:
            groups = _group_queue.get(timeout=2)
            _latest_groups = groups
            last_sync_time = time.time()
        except queue.Empty:
            if _latest_groups and (time.time() - last_sync_time > debounce_seconds):
                sync_group_to_google_sheet(_latest_groups, spreadsheet_id, sheet_name)
                _latest_groups = None

def start_group_sync_worker(spreadsheet_id, sheet_name="Group"):
    t = threading.Thread(target=_group_sync_worker, args=(spreadsheet_id, sheet_name), daemon=True)
    t.start()

def enqueue_group_sync(groups_dict):
    _group_queue.put(groups_dict)